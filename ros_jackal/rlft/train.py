"""
FTRLè®­ç»ƒè„šæœ¬ - VLM+DPT + TD3 (Condorç¦»çº¿æ¨¡å¼)

ä¼˜åŒ–ç‰ˆæœ¬:
1. è‡ªåŠ¨å¯åŠ¨/å…³é—­ tmux VLM æœåŠ¡
2. æ·±åº¦é…ç½®åˆå¹¶ï¼ˆbuffer config + VLM configï¼‰
3. æœåŠ¡å¥åº·æ£€æŸ¥
4. GPU æ™ºèƒ½åˆ†é…
5. å®Œæ•´çš„ä¿¡å·å¤„ç†å’Œæ¸…ç†

çº¯Python 3.10ç¯å¢ƒï¼Œä¸ä¾èµ–gym/ROS
å®Œå…¨æ¨¡ä»¿td3/train.pyçš„Condoræ¨¡å¼ï¼Œä½¿ç”¨InfoEnv + CondorCollector
"""
# ============ GPUé€‰æ‹©å¿…é¡»åœ¨import torchä¹‹å‰ ============
import sys
import os

def _early_gpu_setup():
    """åœ¨import torchä¹‹å‰è§£æ--gpuå‚æ•°å¹¶è®¾ç½®CUDA_VISIBLE_DEVICES"""
    for i, arg in enumerate(sys.argv):
        if arg == '--gpu' and i + 1 < len(sys.argv):
            gpu_id = sys.argv[i + 1]
            os.environ["CUDA_VISIBLE_DEVICES"] = gpu_id
            print(f"[GPU] è®¾ç½® CUDA_VISIBLE_DEVICES={gpu_id} (åœ¨import torchä¹‹å‰)")
            return gpu_id
    return None

_EARLY_GPU = _early_gpu_setup()
# ======================================================

import argparse
import GPUtil
import yaml
import numpy as np
from datetime import datetime
from os.path import join, dirname, abspath, exists
import shutil
import logging
import collections
import time
from pprint import pformat
import signal

import torch
from tensorboardX import SummaryWriter

# æ·»åŠ è·¯å¾„
sys.path.append(dirname(dirname(abspath(__file__))))

# RLFTæ¨¡å— (VLMä¸“ç”¨)
from rlft.vlm_net import VLM_DPT_FeatureExtractor, VLM_DPT_Actor, VLM_DPT_Critic
from rlft.rl import TD3
from rlft.collector import VLMCondorCollector, VLMReplayBuffer

torch.set_num_threads(8)

import psutil
import subprocess
import atexit

# å…¨å±€å˜é‡ï¼šè·Ÿè¸ªå¯åŠ¨çš„ tmux æœåŠ¡
TMUX_SERVICES_STARTED = []
PLANNER = "ddp"  # é»˜è®¤å€¼ï¼Œä¼šåœ¨ main ä¸­æ›´æ–°


def start_tmux_services(config, policy_checkpoint_path=None):
    """
    æ ¹æ®é…ç½®è‡ªåŠ¨å¯åŠ¨ tmux VLM æœåŠ¡

    Args:
        config: åŒ…å« ftrl_config çš„é…ç½®å­—å…¸
        policy_checkpoint_path: ç›´æ¥æŒ‡å®š policy checkpoint è·¯å¾„ï¼ˆä¸ rl.py ä¿æŒä¸€è‡´ï¼‰

    Returns:
        list: å¯åŠ¨çš„ tmux session åç§°åˆ—è¡¨
    """
    global TMUX_SERVICES_STARTED, PLANNER

    ftrl_config = config.get("ftrl_config", {})
    training_config = config.get("training_config", {})

    # æ£€æŸ¥æ˜¯å¦è‡ªåŠ¨å¯åŠ¨
    if not ftrl_config.get("auto_start_services", False):
        print("    >>>> auto_start_services=False, è·³è¿‡è‡ªåŠ¨å¯åŠ¨æœåŠ¡")
        return []

    # è·å–é…ç½®å‚æ•°
    server_urls = ftrl_config.get("server_urls", [])
    num_services = len(server_urls) if server_urls else ftrl_config.get("num_services", 1)
    start_port = ftrl_config.get("start_port", 7000)
    base_model = ftrl_config.get("base_model", "Qwen/Qwen2.5-VL-3B-Instruct")

    # lora_pathï¼šä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„è·¯å¾„ï¼ˆä¸ rl.py save/load ä¿æŒä¸€è‡´ï¼‰
    if policy_checkpoint_path:
        lora_path = policy_checkpoint_path
        print(f"    >>>> ä½¿ç”¨ä¼ å…¥çš„ checkpoint è·¯å¾„: {lora_path}")
    elif 'BUFFER_PATH' in globals() and BUFFER_PATH:
        # å›é€€ï¼šä»å…¨å±€å˜é‡æ„å»ºè·¯å¾„
        lora_path = join(BUFFER_PATH, "policy")
        print(f"    >>>> [å›é€€] ä½¿ç”¨å…¨å±€ BUFFER_PATH æ„å»º: {lora_path}")
    else:
        print("[ERROR] æœªæä¾› checkpoint è·¯å¾„ä¸” BUFFER_PATH æœªè®¾ç½®")
        return []

    # éªŒè¯ checkpoint æ˜¯å¦å­˜åœ¨
    if not exists(lora_path):
        print(f"[ERROR] Checkpoint ç›®å½•ä¸å­˜åœ¨: {lora_path}")
        print(f"[ERROR] è¯·ç¡®ä¿å…ˆè¿è¡Œ policy.save() ä¿å­˜æ¨¡å‹")
        return []

    # æ£€æŸ¥å¿…éœ€æ–‡ä»¶å¹¶æ˜¾ç¤ºè¯¦æƒ…
    print(f"    >>>> éªŒè¯ checkpoint å†…å®¹:")
    checkpoint_files = {
        "LoRA": join(lora_path, "adapter_model.safetensors"),
        "LoRA Config": join(lora_path, "adapter_config.json"),
        "Regression Head": join(lora_path, "regression_head", "pytorch_model.bin"),
        "History Config": join(lora_path, "history_config.json"),
        "History Encoder": join(lora_path, "history_encoder", "pytorch_model.bin"),
        "Normalization": join(lora_path, "normalization", "param_mean.npy"),
    }

    all_ok = True
    for name, filepath in checkpoint_files.items():
        if exists(filepath):
            if name == "LoRA":
                size_mb = os.path.getsize(filepath) / 1024 / 1024
                print(f"         âœ“ {name}: {size_mb:.1f} MB")
            else:
                print(f"         âœ“ {name}")
        else:
            print(f"         âœ— {name} (ç¼ºå¤±)")
            if name in ["LoRA", "Regression Head", "History Config", "Normalization"]:
                all_ok = False

    if not all_ok:
        print(f"[ERROR] Checkpoint ç¼ºå°‘å¿…éœ€æ–‡ä»¶ï¼Œæ— æ³•å¯åŠ¨æœåŠ¡")
        return []

    # ä½¿ç”¨å…¨å±€ PLANNERï¼ˆå·²åœ¨ main ä¸­è®¾ç½®ï¼‰
    planner = PLANNER

    print("\n" + "=" * 60)
    print("  å¯åŠ¨ FTRL VLM æœåŠ¡ (tmux)")
    print("=" * 60)
    print(f"  Planner: {planner}")
    print(f"  Number of services: {num_services}")
    print(f"  Start port: {start_port}")
    print(f"  Base model: {base_model}")
    print(f"  LoRA path: {lora_path}")

    # è·å–è„šæœ¬ç›®å½•
    script_dir = dirname(dirname(abspath(__file__)))
    ft_qwen_dir = join(script_dir, "script", "ft_qwen")
    server_script = join(ft_qwen_dir, "qwen_server.py")

    # æ£€æŸ¥ server è„šæœ¬æ˜¯å¦å­˜åœ¨
    if not exists(server_script):
        print(f"[ERROR] qwen_server.py not found: {server_script}")
        return []

    # æ£€æŸ¥ LoRA checkpoint æ˜¯å¦å­˜åœ¨
    if not exists(lora_path):
        print(f"[ERROR] LoRA checkpoint not found: {lora_path}")
        return []

    # ===== æ–°çš„GPUåˆ†é…é€»è¾‘ï¼šæ”¯æŒæ¯ä¸ªæœåŠ¡å•ç‹¬æŒ‡å®šGPU =====
    # ä¼˜å…ˆä½¿ç”¨ gpu_assignmentsï¼ˆåˆ—è¡¨ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨ gpu_strategyï¼ˆå…¨å±€ç­–ç•¥ï¼‰
    gpu_array = []

    if "gpu_assignments" in ftrl_config:
        # æ–¹å¼1: æ¯ä¸ªæœåŠ¡å•ç‹¬æŒ‡å®šGPUï¼ˆæ¨èï¼‰
        gpu_assignments = ftrl_config["gpu_assignments"]

        if not isinstance(gpu_assignments, list):
            print(f"[ERROR] gpu_assignments must be a list, got {type(gpu_assignments)}")
            return []

        if len(gpu_assignments) != num_services:
            print(f"[ERROR] gpu_assignments length ({len(gpu_assignments)}) must match num_services ({num_services})")
            return []

        gpu_array = [int(g) for g in gpu_assignments]
        print(f"  GPU assignments (per service):")
        for i, gpu in enumerate(gpu_array):
            print(f"    Service {i} -> GPU {gpu}")

    elif "gpu_strategy" in ftrl_config:
        # æ–¹å¼2: ä½¿ç”¨å…¨å±€ç­–ç•¥ï¼ˆå‘åå…¼å®¹ï¼‰
        gpu_strategy = str(ftrl_config["gpu_strategy"])

        if gpu_strategy == "auto":
            # è‡ªåŠ¨é€’å¢åˆ†é…
            try:
                available_gpus = GPUtil.getAvailable(order='memory', limit=8, maxLoad=0.5, maxMemory=0.5)
                if len(available_gpus) < num_services:
                    print(f"  [WARN] Only {len(available_gpus)} GPUs available, requested {num_services}")
                    # å¾ªç¯ä½¿ç”¨å¯ç”¨ GPU
                    gpu_array = [available_gpus[i % len(available_gpus)] for i in range(num_services)]
                else:
                    gpu_array = available_gpus[:num_services]
                print(f"  Auto-detected GPUs: {gpu_array}")
            except Exception as e:
                print(f"  [ERROR] Failed to auto-detect GPUs: {e}")
                print(f"  Falling back to GPU 0")
                gpu_array = [0] * num_services
        elif "," in gpu_strategy:
            gpu_array = [int(g.strip()) for g in gpu_strategy.split(",")]
            if len(gpu_array) != num_services:
                print(f"[ERROR] GPU count ({len(gpu_array)}) must match num_services ({num_services})")
                return []
            print(f"  GPU strategy: {gpu_array}")
        else:
            # å•ä¸ªGPUï¼Œæ‰€æœ‰æœåŠ¡å…±äº«
            gpu_array = [int(gpu_strategy)] * num_services
            print(f"  All services will share GPU {gpu_strategy}")
    else:
        # é»˜è®¤: æ‰€æœ‰æœåŠ¡ä½¿ç”¨GPU 0
        gpu_array = [0] * num_services
        print(f"  Default: All services will use GPU 0")

    print("=" * 60)

    # Conda Python è·¯å¾„ (æ ¹æ®ç¯å¢ƒè°ƒæ•´)
    conda_python_candidates = [
        "/common/home/yl2832/miniconda3/envs/lmms-finetune-qwen/bin/python",
        "/home/yuanjielu/miniforge3/envs/lmms-finetune-qwen/bin/python",
        os.path.expanduser("~/miniconda3/envs/lmms-finetune-qwen/bin/python"),
        os.path.expanduser("~/miniforge3/envs/lmms-finetune-qwen/bin/python"),
    ]
    conda_python = None
    for candidate in conda_python_candidates:
        if exists(candidate):
            conda_python = candidate
            break

    if conda_python is None:
        print("[ERROR] Cannot find lmms-finetune-qwen conda environment")
        print("  Tried:", conda_python_candidates)
        return []

    print(f"  Using Python: {conda_python}")

    started_sessions = []

    for i in range(num_services):
        gpu = gpu_array[i]
        port = start_port + i
        session_name = f"ftrl_{planner}_{i}"

        print(f"\n  Starting service {i+1}/{num_services}...")
        print(f"    Name: {session_name}")
        print(f"    GPU: {gpu}")
        print(f"    Port: {port}")

        # æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
        try:
            result = subprocess.run(
                ["lsof", "-ti", f":{port}"],
                capture_output=True, text=True, timeout=5
            )
            if result.stdout.strip():
                print(f"    [WARN] Port {port} is in use, killing process...")
                subprocess.run(["kill", "-9"] + result.stdout.strip().split(), timeout=5)
                time.sleep(1)
        except Exception as e:
            pass  # lsof å¯èƒ½ä¸å­˜åœ¨æˆ–ç«¯å£æœªè¢«å ç”¨

        # æ£€æŸ¥ tmux session æ˜¯å¦å·²å­˜åœ¨
        try:
            result = subprocess.run(
                ["tmux", "has-session", "-t", session_name],
                capture_output=True, timeout=5
            )
            if result.returncode == 0:
                print(f"    [WARN] tmux session '{session_name}' already exists, killing it...")
                subprocess.run(["tmux", "kill-session", "-t", session_name], timeout=5)
                time.sleep(1)
        except Exception as e:
            pass

        # æ„å»ºå¯åŠ¨å‘½ä»¤
        cmd = f"""export CUDA_VISIBLE_DEVICES={gpu} && \
{conda_python} {server_script} \
    --base_model {base_model} \
    --lora_path {lora_path} \
    --algorithm {planner.upper()} \
    --port {port} \
    --device cuda:0 \
    --load_in_4bit; \
echo 'Service stopped. Press Enter to exit.'; read"""

        # åˆ›å»º tmux session
        try:
            subprocess.run(
                ["tmux", "new-session", "-d", "-s", session_name, cmd],
                check=True, timeout=10
            )
            started_sessions.append(session_name)
            print(f"    [OK] Started in tmux session '{session_name}'")
        except subprocess.CalledProcessError as e:
            print(f"    [ERROR] Failed to start tmux session: {e}")
        except subprocess.TimeoutExpired:
            print(f"    [ERROR] Timeout starting tmux session")

        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œé¿å…åŒæ—¶å¯åŠ¨å¤ªå¤šè¿›ç¨‹
        time.sleep(3)

    TMUX_SERVICES_STARTED = started_sessions

    print("\n" + "=" * 60)
    print(f"  Started {len(started_sessions)}/{num_services} service(s)")
    print("=" * 60)

    # ç­‰å¾…æœåŠ¡å¯åŠ¨å®Œæˆ
    if started_sessions:
        print("\n  ç­‰å¾…æœåŠ¡å¯åŠ¨...")
        wait_time = 15  # ç­‰å¾…30ç§’è®©æœåŠ¡åˆå§‹åŒ–
        for i in range(wait_time):
            print(f"\r  ç­‰å¾…ä¸­... {wait_time - i}s ", end="", flush=True)
            time.sleep(1)
        print("\n  æœåŠ¡åº”è¯¥å·²ç»å¯åŠ¨å®Œæˆ")

    return started_sessions


def stop_tmux_services(session_names=None, planner=None):
    """
    å…³é—­ tmux VLM æœåŠ¡

    Args:
        session_names: è¦å…³é—­çš„ session åç§°åˆ—è¡¨ï¼ŒNone åˆ™å…³é—­æ‰€æœ‰ TMUX_SERVICES_STARTED
        planner: å¦‚æœæŒ‡å®šï¼Œå…³é—­æ‰€æœ‰åŒ¹é… ftrl_{planner}_* çš„ session
    """
    global TMUX_SERVICES_STARTED, PLANNER

    if session_names is None:
        session_names = TMUX_SERVICES_STARTED.copy()

    if planner is None:
        planner = PLANNER

    if not session_names and not planner:
        print("    >>>> æ²¡æœ‰éœ€è¦å…³é—­çš„ tmux æœåŠ¡")
        return

    print("\n" + "=" * 60)
    print("  å…³é—­ FTRL VLM æœåŠ¡ (tmux)")
    print("=" * 60)

    closed_count = 0

    # å…³é—­æŒ‡å®šçš„ session
    for session_name in session_names:
        try:
            result = subprocess.run(
                ["tmux", "has-session", "-t", session_name],
                capture_output=True, timeout=5
            )
            if result.returncode == 0:
                subprocess.run(
                    ["tmux", "kill-session", "-t", session_name],
                    timeout=5
                )
                print(f"  [OK] Closed tmux session: {session_name}")
                closed_count += 1
            else:
                print(f"  [SKIP] Session not found: {session_name}")
        except Exception as e:
            print(f"  [ERROR] Failed to close {session_name}: {e}")

    # é¢å¤–æ£€æŸ¥ï¼šå…³é—­æ‰€æœ‰ ftrl_{planner}_* çš„ session
    if planner:
        try:
            result = subprocess.run(
                ["tmux", "ls"],
                capture_output=True, text=True, timeout=5
            )
            if result.returncode == 0:
                for line in result.stdout.strip().split("\n"):
                    if line and f"ftrl_{planner}_" in line:
                        session = line.split(":")[0]
                        if session not in session_names:
                            try:
                                subprocess.run(
                                    ["tmux", "kill-session", "-t", session],
                                    timeout=5
                                )
                                print(f"  [OK] Closed extra tmux session: {session}")
                                closed_count += 1
                            except:
                                pass
        except:
            pass

    TMUX_SERVICES_STARTED.clear()

    print(f"\n  æ€»å…±å…³é—­äº† {closed_count} ä¸ª tmux session")
    print("=" * 60)


def restart_gazebo():
    print(">>>>>>>> æ­£åœ¨é‡å¯Gazebo...")

    gazebo_processes = ['gazebo', 'gzserver', 'gzclient', 'roslaunch']

    for proc_name in gazebo_processes:
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                if proc.info['name'] == proc_name or \
                        (proc.info['cmdline'] and any(proc_name in cmd for cmd in proc.info['cmdline'])):
                    print(f"    >>>> æ­£åœ¨æ€æ­»è¿›ç¨‹: {proc.info['name']} (PID: {proc.info['pid']})")
                    proc.kill()
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                pass


def deep_merge(base_dict, override_dict, path="", verbose=True):
    """
    æ·±åº¦åˆå¹¶ä¸¤ä¸ªå­—å…¸ï¼Œoverride_dict ä¸­çš„å€¼ä¼šè¦†ç›– base_dict ä¸­çš„ç›¸åŒé”®

    Args:
        base_dict: åŸºç¡€å­—å…¸ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰
        override_dict: è¦†ç›–å­—å…¸
        path: å½“å‰è·¯å¾„ï¼ˆç”¨äºæ—¥å¿—è¾“å‡ºï¼‰
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—

    Returns:
        åˆå¹¶åçš„å­—å…¸ï¼ˆå°±æ˜¯ä¿®æ”¹åçš„ base_dictï¼‰
    """
    for key, value in override_dict.items():
        current_path = f"{path}.{key}" if path else key

        if key in base_dict:
            if isinstance(base_dict[key], dict) and isinstance(value, dict):
                # ä¸¤ä¸ªéƒ½æ˜¯å­—å…¸ï¼Œé€’å½’åˆå¹¶
                deep_merge(base_dict[key], value, current_path, verbose)
            elif base_dict[key] != value:
                # å€¼ä¸åŒï¼Œç”¨ override è¦†ç›–
                old_value = base_dict[key]
                base_dict[key] = value
                if verbose:
                    # åªæ‰“å°é‡è¦çš„é…ç½®å˜æ›´
                    if not isinstance(value, (list, dict)) or len(str(value)) < 100:
                        print(f"    >>>> Override {current_path}: {old_value} -> {value}")
                    else:
                        print(f"    >>>> Override {current_path}: [complex value]")
        else:
            # base ä¸­æ²¡æœ‰è¿™ä¸ªé”®ï¼Œç›´æ¥æ·»åŠ 
            base_dict[key] = value
            if verbose and (not isinstance(value, (list, dict)) or len(str(value)) < 100):
                print(f"    >>>> Add {current_path}: {value}")

    return base_dict


def initialize_config(config_path, save_path, override_config_path=None):
    """
    åŠ è½½é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒç”¨å¦ä¸€ä¸ªé…ç½®è¦†ç›–

    Args:
        config_path: åŸºç¡€é…ç½®æ–‡ä»¶è·¯å¾„
        save_path: ä¿å­˜è·¯å¾„
        override_config_path: è¦†ç›–é…ç½®è·¯å¾„ï¼ˆä¼šè¦†ç›– config_path ä¸­çš„åŒåå‚æ•°ï¼‰
    """
    with open(config_path, 'r') as f:
        config = yaml.load(f, Loader=yaml.FullLoader)

    if config is None:
        print(f"[ERROR] é…ç½®æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯: {config_path}")
        sys.exit(1)

    if override_config_path and exists(override_config_path):
        with open(override_config_path, 'r') as f:
            override_config = yaml.load(f, Loader=yaml.FullLoader)
        if override_config:
            deep_merge(config, override_config, verbose=False)

    config["env_config"]["save_path"] = save_path
    config["env_config"]["config_path"] = config_path

    return config


def initialize_logging(config):
    env_config = config["env_config"]
    training_config = config["training_config"]

    now = datetime.now()
    dt_string = now.strftime("%Y_%m_%d_%H_%M")
    save_path = join(
        env_config["save_path"],
        env_config["env_id"],
        training_config['algorithm'],
        dt_string
    )
    print("    >>>> Saving to %s" % save_path)
    if not exists(save_path):
        os.makedirs(save_path)

    writer = SummaryWriter(save_path)

    shutil.copyfile(
        env_config["config_path"],
        join(save_path, "config.yaml")
    )

    return save_path, writer


def initialize_envs(config):
    """
    åˆå§‹åŒ–ç¯å¢ƒ - Condoræ¨¡å¼ä½¿ç”¨InfoEnv (ä¸éœ€è¦çœŸå®gymç¯å¢ƒ)

    å®Œå…¨æ¨¡ä»¿td3/train.pyçš„é€»è¾‘ï¼Œä½†ç§»é™¤gymä¾èµ–
    """
    env_config = config["env_config"]
    env_id = env_config["env_id"]

    print("    >>>> Using condor mode (offline training)")

    # ç®€åŒ–çš„Spaceç±» - æ›¿ä»£gym.spaces.Box
    class SimpleSpace:
        def __init__(self, low, high, shape, dtype):
            self.low = low
            self.high = high
            self.shape = shape
            self.dtype = dtype

    # åˆ›å»ºInfoEnv - åªæä¾›spaceä¿¡æ¯ï¼Œä¸å®é™…è¿è¡Œä»¿çœŸ
    class InfoEnv:
        def __init__(self, config):
            self.config = config
            env_id = config["env_config"]["env_id"]

            # æ ¹æ®env_idç¡®å®šaction space (å‚æ•° + next_linear_vel + next_angular_vel)
            if "dwa" in env_id.lower():
                action_low = np.array([0.1, 0.314, 3, 10, 0.01, 0.01, 0.1, -0.5, -3.14])
                action_high = np.array([2.0, 3.14, 50, 50, 10.0, 10.0, 0.6, 2.0, 3.14])
            elif "teb" in env_id.lower():
                action_low = np.array([0.1, 0.0, 0.314, 0.1, 0.05, 0.05, 0.1, -0.5, -3.14])
                action_high = np.array([2.0, 1.0, 3.14, 1.0, 0.5, 0.5, 0.6, 2.0, 3.14])
            elif "ddp" in env_id.lower():
                action_low = np.array([0.1, 0.314, 400, 0.01, 0.01, 0.1, -0.5, -3.14])
                action_high = np.array([2.0, 3.14, 800, 0.4, 0.15, 0.6, 2.0, 3.14])
            elif "mppi" in env_id.lower():
                action_low = np.array([0.1, 0.314, 400, 10, 0.01, 0.01, 0.1, 0.1, -0.5, -3.14])
                action_high = np.array([2.0, 3.14, 800, 40, 0.5, 0.5, 2.0, 0.6, 2.0, 3.14])
            else:
                raise ValueError(f"Unknown env_id: {env_id}")

            self.action_space = SimpleSpace(
                low=action_low,
                high=action_high,
                shape=(len(action_low),),
                dtype=np.float32
            )

            # VLMä½¿ç”¨å›¾åƒï¼Œä½†è¿™é‡Œä¸éœ€è¦å®é™…ä½¿ç”¨
            self.observation_space = SimpleSpace(
                low=np.array([0]),
                high=np.array([255]),
                shape=(480, 480, 3),  # RGB costmap
                dtype=np.uint8
            )

    return InfoEnv(config)


def seed(config):
    env_config = config["env_config"]

    np.random.seed(env_config['seed'])
    torch.manual_seed(env_config['seed'])


def initialize_policy(config, env, device_override=None):
    training_config = config["training_config"]

    state_dim = env.observation_space.shape
    action_dim = np.prod(env.action_space.shape)
    action_space_low = env.action_space.low
    action_space_high = env.action_space.high

    if device_override is not None:
        device = device_override
        print(f"    >>>> Using manually specified device: {device}")
    elif "CUDA_VISIBLE_DEVICES" in os.environ:
        device = "cuda:0" if torch.cuda.is_available() else "cpu"
        print(f"    >>>> CUDA_VISIBLE_DEVICES={os.environ['CUDA_VISIBLE_DEVICES']}, using device: {device}")
    else:
        devices = GPUtil.getAvailable(order='first', limit=1, maxLoad=0.8, maxMemory=0.8,
                                      includeNan=False, excludeID=[], excludeUUID=[])
        device = "cuda:%d" % (devices[0]) if len(devices) > 0 else "cpu"
        print(f"    >>>> Auto-selected device: {device}")

    vlm_checkpoint = training_config["vlm_checkpoint_path"]
    print(f"    >>>> Loading VLM+DPT from {vlm_checkpoint}")

    # è·å–ç®—æ³•ç±»å‹ (DWA/TEB/MPPI/DDP)
    algorithm = PLANNER.upper()
    print(f"    >>>> Algorithm: {algorithm}")

    # Actor
    actor_feature_extractor = VLM_DPT_FeatureExtractor(
        checkpoint_path=vlm_checkpoint,
        freeze_vlm=training_config.get("freeze_vlm_actor", True),
        freeze_dpt=training_config.get("freeze_dpt_actor", False),
        freeze_history=training_config.get("freeze_history_actor", None),  # Noneè¡¨ç¤ºè·Ÿéšfreeze_dpt
        device=device,
        use_4bit=True,  # ä½¿ç”¨4-bité‡åŒ–
        algorithm=algorithm  # ä¼ é€’ç®—æ³•ç±»å‹
    )
    actor = VLM_DPT_Actor(
        feature_extractor=actor_feature_extractor,
        action_dim=action_dim,
        algorithm=algorithm  # ä¼ é€’ç»™Actor
    ).to(device)

    actor_optim = torch.optim.Adam(
        filter(lambda p: p.requires_grad, actor.parameters()),
        lr=training_config['actor_lr']
    )

    print("    >>>> Critic sharing Actor's feature extractor with detach protection")
    critic = VLM_DPT_Critic(
        feature_extractor=actor_feature_extractor,  # å…±äº«ï¼ŒVLMåªè¿è¡Œä¸€æ¬¡
        action_dim=action_dim,
        detach_features=True  # é»˜è®¤Trueï¼Œä¿æŠ¤Actorçš„VLMæ›´æ–°
    ).to(device)

    critic_params = []
    for name, param in critic.named_parameters():
        if param.requires_grad and not name.startswith('feature_extractor.'):
            critic_params.append(param)

    critic_optim = torch.optim.Adam(critic_params, lr=training_config['critic_lr'])

    # æ‰“å°å‚æ•°ç»Ÿè®¡
    actor_trainable = sum(p.numel() for p in actor.parameters() if p.requires_grad)
    actor_total = sum(p.numel() for p in actor.parameters())
    print(f"    >>>> Actor: {actor_trainable:,} / {actor_total:,} trainable ({100*actor_trainable/actor_total:.2f}%)")

    critic_trainable = sum(p.numel() for p in critic.parameters() if p.requires_grad)
    critic_total = sum(p.numel() for p in critic.parameters())
    print(f"    >>>> Critic: {critic_trainable:,} / {critic_total:,} trainable ({100*critic_trainable/critic_total:.2f}%)")

    # åŠ è½½å‚æ•°å½’ä¸€åŒ–ç»Ÿè®¡ï¼ˆä»VLM checkpointï¼‰
    param_mean, param_std = None, None
    normalization_dir = os.path.join(vlm_checkpoint, "normalization")
    if os.path.exists(normalization_dir):
        mean_path = os.path.join(normalization_dir, "param_mean.npy")
        std_path = os.path.join(normalization_dir, "param_std.npy")

        if os.path.exists(mean_path) and os.path.exists(std_path):
            param_mean = np.load(mean_path)
            param_std = np.load(std_path)
            print(f"    >>>> Loaded parameter normalization from {normalization_dir}")
            print(f"         Mean: {param_mean}")
            print(f"         Std:  {param_std}")

            # éªŒè¯ç»´åº¦åŒ¹é…
            if len(param_mean) != action_dim or len(param_std) != action_dim:
                print(f"    >>>> WARNING: Normalization dim mismatch!")
                print(f"         Expected {action_dim}, got mean={len(param_mean)}, std={len(param_std)}")
                print(f"         Disabling normalization")
                param_mean, param_std = None, None
        else:
            print(f"    >>>> WARNING: Normalization files not found in {normalization_dir}")
    else:
        print(f"    >>>> INFO: No normalization directory found, using raw parameter space")

    # TD3 policy
    policy = TD3(
        actor, actor_optim,
        critic, critic_optim,
        action_range=[action_space_low, action_space_high],
        device=device,
        param_mean=param_mean,
        param_std=param_std,
        **training_config["policy_args"]
    )

    # VLMä¸“ç”¨ReplayBuffer
    buffer = VLMReplayBuffer(
        state_dim, action_dim,
        training_config['buffer_size'],
        device=device,
        image_size=(400, 600)  # (height, width)
    )

    return policy, buffer


def train(env, policy, buffer, config):
    """è®­ç»ƒä¸»å¾ªç¯ - Condoræ¨¡å¼ï¼ˆå®Œå…¨æ¨¡ä»¿td3/train.pyï¼‰"""
    env_config = config["env_config"]
    training_config = config["training_config"]

    save_path, writer = initialize_logging(config)
    training_args = training_config["training_args"]

    # ä¼ é€’ ftrl_config ç»™ collector
    collector = VLMCondorCollector(
        policy, env, buffer, BUFFER_PATH,
        ftrl_config=config.get("ftrl_config", {})  # ä¼ é€’æœåŠ¡å™¨é…ç½®
    )

    # æ³¨å†Œä¿¡å·å¤„ç†å™¨ï¼Œç¡®ä¿ Ctrl+C æ—¶æ¸…ç†å­è¿›ç¨‹å’Œ tmux æœåŠ¡
    def signal_handler(sig, frame):
        print("\n\n" + "=" * 80)
        print("ğŸ›‘ æ”¶åˆ°é€€å‡ºä¿¡å· (Ctrl+C)ï¼Œæ­£åœ¨æ¸…ç†...")
        print("=" * 80)

        # 1. åœæ­¢æ•°æ®æ”¶é›†å®¹å™¨
        try:
            collector.stop_collection_containers()
            print("âœ“ æ‰€æœ‰æ•°æ®æ”¶é›†å®¹å™¨å·²åœæ­¢")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†æ•°æ®æ”¶é›†å®¹å™¨æ—¶å‡ºç°é”™è¯¯: {e}")

        # 2. åœæ­¢ tmux VLM æœåŠ¡ï¼ˆå¯é…ç½®ï¼‰
        ftrl_config = config.get("ftrl_config", {})
        auto_stop_services = ftrl_config.get("auto_stop_services", True)  # é»˜è®¤å…³é—­

        try:
            if TMUX_SERVICES_STARTED and auto_stop_services:
                stop_tmux_services()
                print("âœ“ æ‰€æœ‰ tmux VLM æœåŠ¡å·²åœæ­¢")
            elif TMUX_SERVICES_STARTED and not auto_stop_services:
                print("â„¹ï¸ tmux VLM æœåŠ¡ä¿æŒè¿è¡Œ (auto_stop_services=False)")
                print(f"   æ‰‹åŠ¨åœæ­¢: tmux kill-session -t vlm_server_*")
            else:
                print("â„¹ï¸ æ²¡æœ‰éœ€è¦åœæ­¢çš„ tmux æœåŠ¡")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç† tmux æœåŠ¡æ—¶å‡ºç°é”™è¯¯: {e}")

        print("=" * 80)
        print("é€€å‡ºè®­ç»ƒ")
        sys.exit(0)

    signal.signal(signal.SIGINT, signal_handler)   # Ctrl+C
    signal.signal(signal.SIGTERM, signal_handler)  # kill å‘½ä»¤

    # æ˜¾ç¤ºä¿¡å·å¤„ç†å™¨é…ç½®
    ftrl_config = config.get("ftrl_config", {})
    auto_stop = ftrl_config.get("auto_stop_services", True)
    print(f"    >>>> ä¿¡å·å¤„ç†å™¨å·²æ³¨å†Œ (Ctrl+C å°†æ¸…ç†å®¹å™¨ï¼ŒtmuxæœåŠ¡={'è‡ªåŠ¨å…³é—­' if auto_stop else 'ä¿æŒè¿è¡Œ'})")

    # å¯åŠ¨æ•°æ®æ”¶é›†å®¹å™¨ï¼ˆåå°æŒç»­è¿è¡Œï¼‰
    # ä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > é…ç½®æ–‡ä»¶ > é»˜è®¤å€¼(False)
    start_containers = ftrl_config.get("start_containers", False)
    if args.start_containers is not None:  # å‘½ä»¤è¡Œè¦†ç›–
        start_containers = args.start_containers

    if start_containers:
        print("\n" + "=" * 80)
        print("å¯åŠ¨æ•°æ®æ”¶é›†å®¹å™¨...")
        print("=" * 80)
        collector.start_collection_containers(mode='train')
        print("=" * 80)
        print("âœ“ æ•°æ®æ”¶é›†å®¹å™¨å·²å¯åŠ¨ï¼Œå°†åœ¨åå°æŒç»­æ”¶é›†æ•°æ®")
        print("=" * 80 + "\n")
    else:
        print("\n" + "=" * 80)
        print("âš ï¸  è·³è¿‡å¯åŠ¨æ•°æ®æ”¶é›†å®¹å™¨ (start_containers=False)")
        print("    å°†ä»å·²æœ‰çš„ buffer æ•°æ®è¿›è¡Œè®­ç»ƒ")
        print("=" * 80 + "\n")

    print("    >>>> Pre-collect experience (Condor mode)")
    print(f"    >>>> Target buffer size: {training_config['pre_collect']} steps")

    # Condor collectï¼šä»actorç›®å½•åŠ è½½è½¨è¿¹
    collector.collect(n_steps=training_config['pre_collect'], status='train')

    print(f"    >>>> Buffer filled! Current size: {buffer.size} steps")
    print(f"    >>>> Starting policy training...")
    print("=" * 80)

    n_steps = 0
    n_iter = 0
    n_ep = 0
    epinfo_buf = collections.deque(maxlen=BUFFER_SIZE)
    world_ep_buf = collections.defaultdict(lambda: collections.deque(maxlen=30))
    t0 = time.time()

    tensorboard_step = 0

    best_episode_length = float('inf')
    best_episode_nav = float('-inf')

    print(f"\n{'='*60}")
    print(f"å¼€å§‹è®­ç»ƒå¾ªç¯ | max_step: {training_args['max_step']} | batch_size: {training_args['batch_size']}")
    print(f"update_per_step: {training_args['update_per_step']} | collect_per_step: {training_args['collect_per_step']}")
    print(f"{'='*60}\n")

    while n_steps < training_args["max_step"]:
        iter_start_time = time.time()
        print(f"\n[Iter {n_iter}] å¼€å§‹ | æ€»æ­¥æ•°: {n_steps}/{training_args['max_step']}")

        # Linear decaying exploration noise
        policy.exploration_noise = \
            - (training_config["exploration_noise_start"] - training_config["exploration_noise_end"]) \
            * n_steps / training_args["max_step"] + training_config["exploration_noise_start"]

        print(f"[Iter {n_iter}] æ”¶é›†è®­ç»ƒæ•°æ®...")
        collect_start = time.time()
        steps, epinfo = collector.collect(training_args["collect_per_step"], status = 'train')
        collect_time = time.time() - collect_start
        print(f"[Iter {n_iter}] æ”¶é›†å®Œæˆ: {steps} steps, {len(epinfo)} episodes, è€—æ—¶: {collect_time:.1f}s")

        n_steps += steps
        n_iter += 1
        n_ep += len(epinfo)
        epinfo_buf.extend(epinfo)

        for d in epinfo:
            world = d["world"].split("/")[-1]
            world_ep_buf[world].append(d)

        actor_grad_norms = []
        critic_grad_norms = []
        actor_losses = []
        critic_losses = []

        print(f"[Iter {n_iter}] å¼€å§‹ç­–ç•¥æ›´æ–° ({training_args['update_per_step']} æ¬¡)...")
        update_start = time.time()
        for update_idx in range(training_args["update_per_step"]):
            update_iter_start = time.time()
            actor_grad_norm, critic_grad_norm, actor_loss, critic_loss = policy.train(buffer,
                                                                                      training_args["batch_size"])
            update_iter_time = time.time() - update_iter_start

            if actor_loss is not None:
                actor_grad_norms.append(actor_grad_norm)
                actor_losses.append(actor_loss)

            critic_grad_norms.append(critic_grad_norm)
            critic_losses.append(critic_loss)

            # æ¯4æ¬¡æ›´æ–°æ‰“å°ä¸€æ¬¡è¿›åº¦ï¼ˆå¶æ•°æ¬¡èƒ½çœ‹åˆ°actor_lossï¼‰
            if (update_idx + 1) % 4 == 0 or update_idx == 0:
                print(f"  æ›´æ–° {update_idx+1}/{training_args['update_per_step']} | "
                      f"critic_loss: {critic_loss:.4f} | "
                      f"actor_loss: {actor_loss if actor_loss else 'N/A'} | "
                      f"è€—æ—¶: {update_iter_time:.2f}s")

        update_time = time.time() - update_start
        print(f"[Iter {n_iter}] ç­–ç•¥æ›´æ–°å®Œæˆ, æ€»è€—æ—¶: {update_time:.1f}s")

        t1 = time.time()
        
        print(f"[Iter {n_iter}] æ”¶é›†æµ‹è¯•æ•°æ®...")
        test_start = time.time()
        test_steps, test_epinfo = collector.collect(n_steps=training_args['collect_per_step'], status='test')
        test_time = time.time() - test_start
        print(f"[Iter {n_iter}] æµ‹è¯•å®Œæˆ: {test_steps} steps, {len(test_epinfo)} episodes, è€—æ—¶: {test_time:.1f}s")

        status_counts = {"success": 0, "flip": 0, "timeout": 0}
        total_episodes = len(epinfo_buf)

        for epinfo in epinfo_buf:
            status = epinfo.get("ep_status", "unknown")
            if status in status_counts:
                status_counts[status] += 1

        success_rate = 100.0 * status_counts["success"] / total_episodes if total_episodes > 0 else 0.0
        flip_rate = 100.0 * status_counts["flip"] / total_episodes if total_episodes > 0 else 0.0
        timeout_rate = 100.0 * status_counts["timeout"] / total_episodes if total_episodes > 0 else 0.0

        nav_metric_score = np.mean([epinfo["nav_metric"] for epinfo in epinfo_buf])

        nav_metrics = [ep['nav_metric'] for ep in test_epinfo]
        avg_nav_metric = sum(nav_metrics) / len(nav_metrics) if nav_metrics else 0

        ep_times = [ep['ep_time'] for ep in test_epinfo]
        avg_ep_time = sum(ep_times) / len(ep_times) if ep_times else 0

        ep_time_steps = [ep['ep_len'] for ep in test_epinfo]
        avg_ep_len = sum(ep_time_steps) / len(ep_time_steps) if ep_time_steps else 0

        log = {
            "Episode_reward": np.mean([epinfo["ep_rew"] for epinfo in epinfo_buf]),
            "Episode_length": np.mean([epinfo["ep_len"] for epinfo in epinfo_buf]),
            "Episode_nav_metric": nav_metric_score,
            "Test_nav_metric": avg_nav_metric,
            "Test_time" : avg_ep_time,
            "Test_length": avg_ep_len,
            "Test_counts": len(nav_metrics),
            "Success_rate": success_rate,
            "Flip_rate": flip_rate,
            "Timeout_rate": timeout_rate,
            "Status_counts": total_episodes,
            "Time": np.mean([epinfo["ep_time"] for epinfo in epinfo_buf]),
            "Collision": np.mean([epinfo["collision"] for epinfo in epinfo_buf]),
            "Actor_grad_norm": np.mean(actor_grad_norms),
            "Critic_grad_norm": np.mean(critic_grad_norms),
            "Actor_loss": np.mean(actor_losses),
            "Critic_loss": np.mean(critic_losses),
            "fps": n_steps / (t1 - t0),
            "n_episode": n_ep,
            "Steps": n_steps,
            "Exploration_noise": policy.exploration_noise
        }

        logging.info(pformat(log))

        if len(epinfo_buf) >= 0:
            current_episode_reward = log["Episode_reward"]
            current_episode_length = log["Test_length"]
            current_episode_nav_metric = log["Test_nav_metric"]

            if (current_episode_nav_metric > best_episode_nav):
                # ä¿å­˜åˆ° policy_step_XXXï¼ˆå†å²è®°å½•ï¼‰
                policy_name = f"policy_step_{tensorboard_step}"
                policy.save(save_path, policy_name)

                # ä¿å­˜åˆ° best_modelï¼ˆå›ºå®šç›®å½•ï¼Œæ–¹ä¾¿æŸ¥æ‰¾æœ€ä½³æ¨¡å‹ï¼‰
                policy.save(save_path, "best_model")
                print(f"    >>>> ğŸ’¾ æ–°çš„æœ€ä½³æ¨¡å‹! Test_nav_metric: {current_episode_nav_metric:.3f} (ä¹‹å‰: {best_episode_nav:.3f})")
                print(f"    >>>> å·²ä¿å­˜åˆ°: {join(save_path, 'best_model')}")

                # è®°å½•æœ€ä½³æ€§èƒ½ä¿¡æ¯
                with open(join(save_path, f"best_performance_step_{tensorboard_step}.txt"), 'w') as f:
                    f.write(f"Best Performance at TensorBoard Step {tensorboard_step}:\n")
                    f.write(f"Training Step: {n_steps}\n")
                    f.write(f"Episode Reward: {current_episode_reward:.3f}\n")
                    f.write(f"Episode Length: {current_episode_length:.3f}\n")
                    f.write(f"Success Rate: {success_rate:.3f}%\n")
                    f.write(f"Test_nav_metric: {current_episode_nav_metric:.3f}\n")

                # æ›´æ–° best_model çš„å…ƒä¿¡æ¯
                with open(join(save_path, "best_model", "best_info.txt"), 'w') as f:
                    f.write(f"Best Model Info\n")
                    f.write(f"===============\n")
                    f.write(f"TensorBoard Step: {tensorboard_step}\n")
                    f.write(f"Training Step: {n_steps}\n")
                    f.write(f"Test_nav_metric: {current_episode_nav_metric:.3f}\n")
                    f.write(f"Episode Reward: {current_episode_reward:.3f}\n")
                    f.write(f"Episode Length: {current_episode_length:.3f}\n")
                    f.write(f"Success Rate: {success_rate:.3f}%\n")
                    f.write(f"Saved at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

                best_episode_nav = current_episode_nav_metric
                best_episode_length = current_episode_length

            if n_iter % training_config["log_intervals"] == 0:
                for k in log.keys():
                    writer.add_scalar('train/' + k, log[k], global_step=tensorboard_step)

                for k in world_ep_buf.keys():
                    writer.add_scalar(k + "/Episode_reward", np.mean([epinfo["ep_rew"] for epinfo in world_ep_buf[k]]),
                                      global_step=tensorboard_step)
                    writer.add_scalar(k + "/Episode_length", np.mean([epinfo["ep_len"] for epinfo in world_ep_buf[k]]),
                                      global_step=tensorboard_step)
                    writer.add_scalar(k + "/Episode_nav_metric", np.mean([epinfo["nav_metric"] for epinfo in world_ep_buf[k]]),
                                      global_step=tensorboard_step)
                    writer.add_scalar(k + "/Success_rate", success_rate,
                                      global_step=tensorboard_step)
                    writer.add_scalar(k + "/Flip_rate", flip_rate,
                                      global_step=tensorboard_step)
                    writer.add_scalar(k + "/Timeout_rate", timeout_rate,
                                      global_step=tensorboard_step)
                    writer.add_scalar(k + "/Status_counts", total_episodes,
                                      global_step=tensorboard_step)
                    writer.add_scalar(k + "/Time", np.mean([epinfo["ep_time"] for epinfo in world_ep_buf[k]]),
                                      global_step=tensorboard_step)
                    writer.add_scalar(k + "/Collision", np.mean([epinfo["collision"] for epinfo in world_ep_buf[k]]),
                                      global_step=tensorboard_step)

            tensorboard_step += steps

    # Condoræ¨¡å¼ï¼šæ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    # shutil.rmtree(BUFFER_PATH, ignore_errors=True)
    print("    >>>> Training completed!")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description = 'Start training')
    parser.add_argument('--config_path', dest='config_path', default="../script/ft_qwen/configs/")
    parser.add_argument('--config_file', dest='config_file', default="ftrl_vlm_ddp")
    parser.add_argument('--buffer_path', dest='buffer_path', default="../buffer/")
    parser.add_argument('--model_path', dest='model_path', default="../model_rlft/",
                        help='Path to load checkpoints (e.g., ../model_ftrl/)')
    parser.add_argument('--logging_path', dest='logging_path', default="../logging/")
    parser.add_argument('--buffer_size', dest='buffer_size', default= 200)
    parser.add_argument('--device', dest='device', default="cuda:0")
    parser.add_argument('--gpu', dest='gpu', type=int, default=None,
                        help='GPU ID to use (e.g., --gpu 1). Sets CUDA_VISIBLE_DEVICES.')
    parser.add_argument('--policy_name', dest='policy_name', default="ddp_rlft",
                        help='Policy name for buffer directory (e.g., dwa_ftrl)')
    parser.add_argument('--planner', dest='planner', default=None,
                        help='Planner name for checkpoint directory (e.g., DWA, TEB, DDP, MPPI)')
    parser.add_argument('--start_containers', dest='start_containers', default=None, type=lambda x: x.lower() == 'true',
                        help='Start collection containers (default: from config file, see ftrl_config.start_containers)')
    parser.add_argument('--start_services', dest='start_services', default=None, type=lambda x: x.lower() == 'true',
                        help='Auto start tmux VLM services (default: from config file, see ftrl_config.auto_start_services)')

    logging.getLogger().setLevel("INFO")
    args = parser.parse_args()

    # ===== GPU è®¾ç½® =====
    # æ³¨æ„: CUDA_VISIBLE_DEVICES å·²åœ¨æ–‡ä»¶å¼€å¤´ import torch ä¹‹å‰è®¾ç½®
    if args.gpu is not None:
        args.device = "cuda:0"  # CUDA_VISIBLE_DEVICES åï¼Œcuda:0 å°±æ˜¯æŒ‡å®šçš„ GPU
        print(f"[GPU] ä½¿ç”¨ GPU {args.gpu} (å®é™…è®¾å¤‡: cuda:0)")

    BUFFER_BASE_PATH = args.buffer_path   # e.g., ../buffer/
    MODEL_PATH = args.model_path           # e.g., ../model_rlft/
    BUFFER_SIZE = args.buffer_size
    SAVE_PATH = args.logging_path          # e.g., ../logging/
    policy_name = args.policy_name
    VLM_CONFIG_PATH = args.config_path
    VLM_CONFIG_NAME = args.config_file

    # ===== æ£€æŸ¥å‚æ•°å’ŒåŠ è½½é…ç½® =====
    if not policy_name:
        print("[ERROR] --policy_name æ˜¯å¿…é¡»å‚æ•°")
        sys.exit(1)

    BUFFER_PATH = join(BUFFER_BASE_PATH, policy_name)
    vlm_config_file = join(VLM_CONFIG_PATH, VLM_CONFIG_NAME + ".yaml")
    buffer_config_file = join(BUFFER_PATH, "config.yaml")

    if not exists(vlm_config_file):
        print(f"[ERROR] VLM é…ç½®ä¸å­˜åœ¨: {vlm_config_file}")
        sys.exit(1)

    if not exists(BUFFER_PATH):
        os.makedirs(BUFFER_PATH)

    # buffer å¿…é¡»æœ‰ configï¼Œç”¨ VLM config è¦†ç›–
    if not exists(buffer_config_file):
        print(f"[ERROR] Buffer é…ç½®ä¸å­˜åœ¨: {buffer_config_file}")
        sys.exit(1)

    config = initialize_config(buffer_config_file, SAVE_PATH, override_config_path=vlm_config_file)

    ACTION_TYPE = config["env_config"].get("action_type", "DDP")
    PLANNER = args.planner.lower() if args.planner else ACTION_TYPE.split('_')[0].lower()

    print(f"[Config] policy={policy_name}, planner={PLANNER}, buffer={BUFFER_PATH}")

    # ===== Step 2: åˆå§‹åŒ–ç¯å¢ƒå’Œç­–ç•¥ =====
    print("\n" + "=" * 80)
    print("Step 2: åˆå§‹åŒ–ç¯å¢ƒå’Œç­–ç•¥")
    print("=" * 80)
    seed(config)
    print("    >>>> Creating the environments (Condor mode)")
    env = initialize_envs(config)

    print("    >>>> Initializing the policy")
    policy, buffer = initialize_policy(config, env, device_override=args.device)

    # åŠ è½½ RLFT checkpointï¼ˆå¦‚æœæœ‰ï¼‰
    policy.load(BUFFER_PATH, "policy")

    # ç«‹å³ä¿å­˜åˆ° bufferï¼Œç¡®ä¿ VLM æœåŠ¡å™¨æœ‰å®Œæ•´çš„ checkpoint å¯ç”¨
    print("    >>>> Saving policy to buffer (ç¡®ä¿ VLM æœåŠ¡å™¨å¯è®¿é—®)")
    policy.save(BUFFER_PATH, "policy")

    # è®¡ç®— policy checkpoint è·¯å¾„ï¼ˆä¸ rl.py ä¸­çš„ save/load é€»è¾‘ä¸€è‡´ï¼‰
    policy_checkpoint_path = join(BUFFER_PATH, "policy")
    print(f"         Checkpoint å·²ä¿å­˜åˆ°: {policy_checkpoint_path}")

    # ===== Step 4: å¯åŠ¨ tmux VLM æœåŠ¡ =====
    # ä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > é…ç½®æ–‡ä»¶ > é»˜è®¤å€¼(True)
    start_services = config.get("ftrl_config", {}).get("auto_start_services", True)
    if args.start_services is not None:  # å‘½ä»¤è¡Œè¦†ç›–
        start_services = args.start_services

    if start_services:
        print("\n" + "=" * 80)
        print("Step 4: å¯åŠ¨ tmux VLM æœåŠ¡")
        print("=" * 80)
        # ä¼ é€’å®é™…çš„ checkpoint è·¯å¾„ï¼ˆä¸ rl.py ä¿æŒä¸€è‡´ï¼‰
        started_services = start_tmux_services(config, policy_checkpoint_path=policy_checkpoint_path)
        if started_services:
            print(f"    >>>> âœ“ Started {len(started_services)} tmux VLM services")
            # æ³¨å†Œ atexit æ¸…ç†å‡½æ•°ï¼Œç¡®ä¿ç¨‹åºé€€å‡ºæ—¶å…³é—­æœåŠ¡
            atexit.register(stop_tmux_services)
        else:
            print("    >>>> âœ— No tmux services started (check config or errors above)")
    else:
        print("\n" + "=" * 80)
        print("Step 4: è·³è¿‡å¯åŠ¨ tmux VLM æœåŠ¡ (--start_services=False)")
        print("=" * 80)

    # ===== Step 5: å¼€å§‹è®­ç»ƒ =====
    print("\n" + "=" * 80)
    print("Step 5: å¼€å§‹è®­ç»ƒ")
    print("=" * 80)
    train(env, policy, buffer, config)
